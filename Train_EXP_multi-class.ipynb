{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foresight\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\foresight\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\foresight\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.cuda import amp\n",
    "import timm\n",
    "from pytorch_toolbelt.inference import tta\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "from augmentation import *\n",
    "from monai.inferers import sliding_window_inference\n",
    "from tifffile import imread\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.PadIfNeeded(min_height=CFG['window_size'], min_width=CFG['window_size'], p=1),\n",
    "        A.RandomCrop(CFG['window_size'], CFG['window_size'], p=1),\n",
    "        \n",
    "        A.OneOf([\n",
    "            A.HueSaturationValue(hue_shift_limit=100, sat_shift_limit=15, val_shift_limit=10, p=0.7),\n",
    "            A.CLAHE(clip_limit=2, p=0.3),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "        ], p=0.9),\n",
    "        \n",
    "        A.Blur(blur_limit= 2, p=0.3),\n",
    "        A.GaussNoise(p=0.3),\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        \n",
    "#         A.OneOf([\n",
    "#             A.GridDistortion(num_steps=5, distort_limit=0.5, p=1.0),\n",
    "#             A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "#         ], p=0.7),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2, rotate_limit= 15,\n",
    "                                        interpolation=cv2.INTER_LINEAR, border_mode=0, p=0.9),\n",
    "        A.CoarseDropout(max_holes=8, max_height=CFG['window_size']//20, max_width=CFG['window_size']//20,\n",
    "                        min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0),\n",
    "    ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape, color=1):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = color\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def read_data(data, mode):\n",
    "    ## read img\n",
    "    img_path= data['image_path']\n",
    "    if CFG['domain_shift'] and mode=='train' and np.random.rand()<CFG['domain_shift']:\n",
    "        img_path= img_path.replace('train_images', 'train_images_domain_shift')\n",
    "    try: img= imread(img_path)\n",
    "    except: img= np.array(Image.open(img_path))\n",
    "    \n",
    "    ## read mask\n",
    "    mask= rle_decode(data['rle'], img.shape[:2])\n",
    "    mask= np.expand_dims(mask, axis= 2)\n",
    "    \n",
    "    ## organ type\n",
    "    organ= data['organ']\n",
    "    \n",
    "    ## make cls mask\n",
    "    mask*= choose_organ.index(organ)+1\n",
    "    \n",
    "    return img, mask, organ\n",
    "\n",
    "\n",
    "class custom_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, transforms,\n",
    "                 mode='valid',\n",
    "                 cutmix=False,\n",
    "                 mixup=False,\n",
    "                 mosaic=False,\n",
    "                 copypaste=False):\n",
    "        self.dataset= dataset\n",
    "        self.transforms= transforms\n",
    "        self.mode= mode\n",
    "        self.cutmix= cutmix\n",
    "        self.mixup= mixup\n",
    "        self.mosaic= mosaic\n",
    "        self.copypaste= copypaste\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data= self.dataset.loc[index]\n",
    "        img, mask, organ= read_data(data, self.mode)\n",
    "        \n",
    "        ## scale adjust\n",
    "        img_size= min(img.shape[0], img.shape[1])\n",
    "        img_size= img_size//CFG['img_scale']\n",
    "        img_size= CFG['window_size'] if img_size < CFG['window_size'] else img_size\n",
    "        img= cv2.resize(img, (img_size, img_size))\n",
    "        mask= cv2.resize(mask, (img_size, img_size))\n",
    "        mask= np.expand_dims(mask, axis= 2)\n",
    "        \n",
    "        ## augmentation\n",
    "        while True:\n",
    "            aug= self.transforms(image= img, mask= mask)\n",
    "            aug_img, aug_mask= aug['image'], aug['mask']\n",
    "            if aug_mask.numpy().any(): break\n",
    "        img, mask= aug_img, aug_mask\n",
    "        \n",
    "        # use mosaic\n",
    "        if self.mosaic and np.random.rand() >= (1-self.mosaic) and organ!='lung':\n",
    "            img_1= img.permute(1,2,0).numpy()\n",
    "            mask_1= np.array(mask)\n",
    "            imgs, masks= [], []\n",
    "            imgs.append(img_1)\n",
    "            masks.append(mask_1)\n",
    "            for i in range(3):\n",
    "                while True:\n",
    "                    indx= np.random.randint(len(self.dataset))\n",
    "                    data= self.dataset.loc[indx]\n",
    "                    img_2, mask_2, organ_2= read_data(data, self.mode)\n",
    "                    if organ_2!='lung': break\n",
    "                imgs.append(img_2)\n",
    "                masks.append(mask_2)\n",
    "            img, mask= mosaic_aug(imgs[0].shape[0],\n",
    "                                  CFG['window_size'],\n",
    "                                  imgs[0], masks[0],\n",
    "                                  imgs[1], masks[1],\n",
    "                                  imgs[2], masks[2],\n",
    "                                  imgs[3], masks[3])\n",
    "            img= torch.tensor(img, dtype= torch.float32).permute(2,0,1)\n",
    "            \n",
    "        # use mixup\n",
    "        if self.mixup and np.random.rand() >= (1-self.mixup):\n",
    "            img_1= img.permute(1,2,0).numpy()\n",
    "            mask_1= np.array(mask)\n",
    "            indx= np.random.randint(len(self.dataset))\n",
    "            data= self.dataset.loc[indx]\n",
    "            img_2, mask_2= read_data(data)\n",
    "            img, mask= mixup_aug(img_1.shape[0], \n",
    "                                 CFG['window_size'],\n",
    "                                 img_1, mask_1, \n",
    "                                 img_2, mask_2)\n",
    "            img= torch.tensor(img, dtype= torch.float32).permute(2,0,1)\n",
    "            \n",
    "        # use cutmix\n",
    "        if self.cutmix and np.random.rand() >= (1-self.cutmix) and organ!='lung':\n",
    "            img_1= img.permute(1,2,0).numpy()\n",
    "            mask_1= np.array(mask)\n",
    "            while True:\n",
    "                indx= np.random.randint(len(self.dataset))\n",
    "                data= self.dataset.loc[indx]\n",
    "                img_2, mask_2, organ_2= read_data(data, self.mode)\n",
    "                if organ_2!='lung': break\n",
    "            img, mask= cutmix_aug(img_1.shape[0], \n",
    "                                  CFG['window_size'],\n",
    "                                  img_1, mask_1, \n",
    "                                  img_2, mask_2)\n",
    "            img= torch.tensor(img, dtype= torch.float32).permute(2,0,1)\n",
    "            \n",
    "        # use copypaste\n",
    "        if self.copypaste and np.random.rand() >= (1-self.copypaste):\n",
    "            img_1= img.permute(1,2,0).numpy()\n",
    "            mask_1= np.array(mask)\n",
    "            while True:\n",
    "                indx= np.random.randint(len(self.dataset))\n",
    "                data= self.dataset.loc[indx]\n",
    "                img_2, mask_2= read_data(data)\n",
    "                if mask_2.any(): break\n",
    "            img, mask= copy_paste(img_1.shape[0], \n",
    "                                  CFG['window_size'],\n",
    "                                  img_1, mask_1, \n",
    "                                  img_2, mask_2)\n",
    "            img= torch.tensor(img, dtype= torch.float32).permute(2,0,1)\n",
    "\n",
    "        mask= torch.tensor(mask, dtype= torch.int64)\n",
    "        mask= mask.permute(2,0,1)\n",
    "\n",
    "        ## aux label\n",
    "        if CFG['aux']:\n",
    "            aux_label= np.zeros((len(mask),))\n",
    "            for i in range(len(mask)):\n",
    "                if mask[i].numpy().any(): \n",
    "                    aux_label[i]= 1\n",
    "        else:\n",
    "            aux_label= [-1]\n",
    "            \n",
    "        if CFG['amp']: return img/255, mask, aux_label\n",
    "        else: return img/255, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_loss(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        self.JaccardLoss = smp.losses.JaccardLoss(mode='multiclass')\n",
    "        self.DiceLoss    = smp.losses.DiceLoss(mode='multiclass', from_logits=True)\n",
    "        self.BCELoss     = smp.losses.SoftBCEWithLogitsLoss()\n",
    "        self.CELosss     = smp.losses.SoftCrossEntropyLoss(smooth_factor= 0)\n",
    "        self.LovaszLoss  = smp.losses.LovaszLoss(mode='multiclass', per_image=False)\n",
    "        self.TverskyLoss = smp.losses.TverskyLoss(mode='multiclass', log_loss=False, from_logits=True)\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss= 1.0*self.DiceLoss(y_pred, y_true)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_amp(dataloader, model, criterion, optimizer):\n",
    "    scaler= amp.GradScaler()\n",
    "    model.train()\n",
    "\n",
    "    ep_loss= []\n",
    "    for i, (imgs, masks, aux_labels) in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= imgs.to('cuda')\n",
    "        masks= masks.to('cuda')\n",
    "        if CFG['aux']: aux_labels= aux_labels.to('cuda')\n",
    "        \n",
    "        with amp.autocast():\n",
    "            preds= model(imgs)\n",
    "            masks= torch.squeeze(masks)\n",
    "            \n",
    "            if CFG['aux']:\n",
    "                loss_1= criterion(preds[0], masks)\n",
    "                loss_2= criterion(preds[1], aux_labels)\n",
    "                loss= (1-CFG['aux'])*loss_1 + CFG['aux']*loss_2\n",
    "            else:\n",
    "                loss= criterion(preds, masks)\n",
    "            ep_loss.append(loss.item())\n",
    "            loss/= CFG['gradient_accumulation']\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i+1) % CFG['gradient_accumulation']== 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "    return np.mean(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch_amp(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    ep_loss= []\n",
    "    masks_dice= []\n",
    "    auxs_dice= []\n",
    "    for i, (imgs, masks, aux_label) in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= imgs.to('cuda')\n",
    "        masks= masks.to('cuda')\n",
    "        if CFG['aux']: aux_label= aux_label.to('cuda')\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            preds= sliding_window_inference(imgs, \n",
    "                                            (CFG['window_size'], CFG['window_size']), \n",
    "                                            sw_batch_size= 2, \n",
    "                                            predictor= model, \n",
    "                                            mode= 'gaussian',\n",
    "                                            overlap= 0.25)\n",
    "            if CFG['aux']:\n",
    "                loss_1= criterion(preds[0], masks)\n",
    "                loss_2= criterion(preds[1], aux_label)\n",
    "                loss= (1-CFG['aux'])*loss_1 + CFG['aux']*loss_2\n",
    "            else:\n",
    "                loss= criterion(preds, masks)\n",
    "            ep_loss.append(loss.item())\n",
    "            \n",
    "        ## evaluation\n",
    "        if CFG['aux']: pred_mask= preds[0].cpu()\n",
    "        else: pred_mask= preds.cpu()\n",
    "        mask_dice= loss.item()\n",
    "        masks_dice.append(mask_dice)\n",
    "            \n",
    "        if CFG['aux']:\n",
    "            pred_aux= preds[1].cpu()\n",
    "            aux_dice= dice( pred_aux, aux_label.cpu() )\n",
    "            auxs_dice.append(aux_dice)\n",
    "        \n",
    "    ## metrice\n",
    "    dice_mask= 1 - np.mean(masks_dice)\n",
    "    dice_aux= 1 - np.mean(auxs_dice) if CFG['aux'] else None\n",
    "        \n",
    "    return np.mean(ep_loss), dice_mask, dice_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'fold': 0,\n",
    "    'epoch': 100,\n",
    "    'img_scale': 4,\n",
    "    'window_size': 768,\n",
    "    'model_name': 'timm-efficientnet-b7',\n",
    "    'aux': False,\n",
    "    'classes_balance': True,\n",
    "    'finetune': False,\n",
    "    'domain_shift': 0.5,\n",
    "    \n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 0,\n",
    "    'batch_size': 4,\n",
    "    'gradient_accumulation': 2,\n",
    "    'amp': True,\n",
    "    \n",
    "    'cutmix': 0.5,\n",
    "    'mixup': False,\n",
    "    'mosaic': 0.5,\n",
    "    'copypaste': False,\n",
    "    \n",
    "    'load_model': False,\n",
    "    'save_model': 'train_model',\n",
    "}\n",
    "if CFG['aux']!=False: CFG['amp']= True\n",
    "if CFG['finetune']:\n",
    "    print('finetune')\n",
    "    CFG['epoch']= 20\n",
    "    CFG['lr']= 5e-5\n",
    "    CFG['load_model']= f\"train_model/model_cv{CFG['fold']}_best.pth\"\n",
    "    \n",
    "# CFG['load_model']= f\"test_model/effb7_w768_cls_0.51/model_cv{CFG['fold']}_best.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance classes\n",
      "train dataset: 395\n",
      "valid dataset: 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>rle</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>image_path</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10044</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Data/train_images/10044.tiff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10274</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Data/train_images/10274.tiff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10392</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Data/train_images/10392.tiff</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10488</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Data/train_images/10488.tiff</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10610</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>478925 68 481909 87 484893 105 487863 154 4908...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Data/train_images/10610.tiff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     id     organ data_source  img_height  img_width  pixel_size  \\\n",
       "0      0  10044  prostate         HPA        3000       3000         0.4   \n",
       "1      1  10274  prostate         HPA        3000       3000         0.4   \n",
       "2      2  10392    spleen         HPA        3000       3000         0.4   \n",
       "3      3  10488      lung         HPA        3000       3000         0.4   \n",
       "4      4  10610    spleen         HPA        3000       3000         0.4   \n",
       "\n",
       "   tissue_thickness                                                rle   age  \\\n",
       "0                 4  1459676 77 1462675 82 1465674 87 1468673 92 14...  37.0   \n",
       "1                 4  715707 2 718705 8 721703 11 724701 18 727692 3...  76.0   \n",
       "2                 4  1228631 20 1231629 24 1234624 40 1237623 47 12...  82.0   \n",
       "3                 4  3446519 15 3449517 17 3452514 20 3455510 24 34...  78.0   \n",
       "4                 4  478925 68 481909 87 484893 105 487863 154 4908...  21.0   \n",
       "\n",
       "      sex                    image_path  fold  \n",
       "0    Male  Data/train_images/10044.tiff     3  \n",
       "1    Male  Data/train_images/10274.tiff     3  \n",
       "2    Male  Data/train_images/10392.tiff     4  \n",
       "3    Male  Data/train_images/10488.tiff    -1  \n",
       "4  Female  Data/train_images/10610.tiff     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('./Data/train.csv')\n",
    "\n",
    "## choose organ\n",
    "choose_organ= [\n",
    "    'lung',\n",
    "    'spleen',\n",
    "    'prostate',\n",
    "    'kidney',\n",
    "    'largeintestine',\n",
    "]\n",
    "df= df[df['organ'].isin(choose_organ)]\n",
    "df.loc[ df['organ']=='lung', 'fold' ]= -1\n",
    "\n",
    "train_df= df[df['fold']!=CFG['fold']].reset_index()\n",
    "valid_df= df[df['fold']==CFG['fold']].reset_index()\n",
    "\n",
    "## classes balance\n",
    "if CFG['classes_balance']:\n",
    "    print('balance classes')\n",
    "    max_sample= len(train_df[train_df['organ']=='kidney'])\n",
    "    for organ in choose_organ:\n",
    "        fill_num= max_sample - len(train_df[train_df['organ']==organ])\n",
    "        if fill_num:\n",
    "            df= train_df[train_df['organ']==organ].reset_index(drop=True)\n",
    "            try: sample_df= df.sample(n= fill_num, replace= False)\n",
    "            except: sample_df= df.sample(n= fill_num, replace= True)\n",
    "            train_df= pd.concat([train_df, sample_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(f'train dataset: {len(train_df)}')\n",
    "print(f'valid dataset: {len(valid_df)}')\n",
    "\n",
    "train_dataset= custom_dataset(train_df,\n",
    "                              get_train_transform(),\n",
    "                              mode= 'train',\n",
    "                              cutmix= CFG['cutmix'],\n",
    "                              mixup= CFG['mixup'],\n",
    "                              mosaic= CFG['mosaic'],\n",
    "                              copypaste= CFG['copypaste'])\n",
    "valid_dataset= custom_dataset(valid_df, get_test_transform())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size= CFG['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size= 1, shuffle=False, num_workers=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_dataset= custom_dataset(train_df,\n",
    "                              get_train_transform(),\n",
    "                              mode= 'train',\n",
    "                              cutmix= CFG['cutmix'],\n",
    "                              mixup= CFG['mixup'],\n",
    "                              mosaic= CFG['mosaic'],\n",
    "                              copypaste= CFG['copypaste'])\n",
    "\n",
    "data= train_dataset[0]\n",
    "img= data[0].permute(1,2,0).numpy()\n",
    "mask= data[1].permute(1,2,0).numpy()\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.imshow(mask, vmin=0, vmax=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d7c92b8c424c12abca0e24dfdb3ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foresight\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6a7719fde8496cbadea8805152caeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.81544\n",
      "valid_loss: 0.60536,                vali_score: 0.39464,                valid_aux: None\n",
      "Model saved at:  0.39464\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba591704159449687eab44261e74b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8d2eff8751487a8fd7650bf1eb03bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.69265\n",
      "valid_loss: 0.53361,                vali_score: 0.46639,                valid_aux: None\n",
      "Model saved at:  0.46639\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe6313bd58f4962bd5f9992948e572f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d9df7cb4bc4bf7928df7972a0ba12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5861\n",
      "valid_loss: 0.5116,                vali_score: 0.4884,                valid_aux: None\n",
      "Model saved at:  0.4884\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cdb4c6f61c44ec9b867b9ef53bc8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9a5a4f7d9348148493b4d02cde7092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5445\n",
      "valid_loss: 0.50339,                vali_score: 0.49661,                valid_aux: None\n",
      "Model saved at:  0.49661\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678a724e0e5748728dc6cc2d8ff58975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f86bb4c6bfd47a486244296e1cbce15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.52949\n",
      "valid_loss: 0.49964,                vali_score: 0.50036,                valid_aux: None\n",
      "Model saved at:  0.50036\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009d5a83ed414b039f58e0f57bc854e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2735c0de7f47bcb130d96da329b86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.51995\n",
      "valid_loss: 0.50197,                vali_score: 0.49803,                valid_aux: None\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3806de7b9baa462a8da7a828d91437ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59155845431744cb9239eea410edbcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.50316\n",
      "valid_loss: 0.47697,                vali_score: 0.52303,                valid_aux: None\n",
      "Model saved at:  0.52303\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672c13e803504f1f81a063561e96de97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d905bdb53b9430ba650d5701090ab36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.44957\n",
      "valid_loss: 0.45952,                vali_score: 0.54048,                valid_aux: None\n",
      "Model saved at:  0.54048\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f891d3d2ef4521bc4c717c1f3421e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa4321e6e2f45c6bd920f11b91e1ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.42677\n",
      "valid_loss: 0.45359,                vali_score: 0.54641,                valid_aux: None\n",
      "Model saved at:  0.54641\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519a38001fdf42dc89f87ee05cc2df95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e0713300444abcbe5810157e426c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.41001\n",
      "valid_loss: 0.45317,                vali_score: 0.54683,                valid_aux: None\n",
      "Model saved at:  0.54683\n",
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ec85a578ad46bf82ae063240272832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c8ff12c9a04b68b2c2b4b880faf66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.41985\n",
      "valid_loss: 0.45006,                vali_score: 0.54994,                valid_aux: None\n",
      "Model saved at:  0.54994\n",
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07294479350f43d6ae5a3269f8cf9df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fa63776d574a0f8f5933acd6e2e9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.39407\n",
      "valid_loss: 0.44853,                vali_score: 0.55147,                valid_aux: None\n",
      "Model saved at:  0.55147\n",
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63227b1497094c83a925c594399b4165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084df91a4f724a6582b5d7120780be23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.38123\n",
      "valid_loss: 0.44997,                vali_score: 0.55003,                valid_aux: None\n",
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bd2f9fe83a4082b7ae7d8e0bcb235d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ENCODER = CFG['model_name']\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = None # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "aux_params=dict(\n",
    "    pooling='avg',             # one of 'avg', 'max'\n",
    "    dropout=0.5,               # dropout ratio, default is None\n",
    "    activation=None,      # activation function, default is None\n",
    "    classes=1,                 # define number of output labels\n",
    ") if CFG['aux'] != False else None\n",
    "\n",
    "if not CFG['load_model']:\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER, \n",
    "        encoder_weights=ENCODER_WEIGHTS, \n",
    "        classes= 6, \n",
    "        in_channels= 3,\n",
    "        activation=ACTIVATION,\n",
    "        aux_params=aux_params,\n",
    "        #decoder_attention_type= 'scse',\n",
    "    )\n",
    "else:\n",
    "    print(f\"load_model: {CFG['load_model']}\")\n",
    "    model= torch.load(CFG['load_model'])\n",
    "\n",
    "## loss\n",
    "loss= custom_loss()\n",
    "loss.__name__ = 'custom_loss'\n",
    "dice= L.DiceLoss(mode= 'multiclass')\n",
    "dice.__name__= 'dice_loss'\n",
    "\n",
    "metrics = [\n",
    "#     smp.utils.metrics.Fscore(threshold= 0.5, activation= 'sigmoid'),\n",
    "    smp.utils.metrics.IoU(threshold=0.5, activation= 'sigmoid'),\n",
    "    dice,\n",
    "]\n",
    "optimizer = torch.optim.AdamW([ \n",
    "    dict(params=model.parameters(), lr=CFG['lr']),\n",
    "], weight_decay= CFG['weight_decay'])\n",
    "\n",
    "\n",
    "model.train()\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "max_score = 0\n",
    "for i in range(1, CFG['epoch']+1):\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    \n",
    "    ## train\n",
    "    if CFG['amp']: \n",
    "        train_loss= train_epoch_amp(train_loader, model, loss, optimizer)\n",
    "        valid_loss, dice_mask, dice_aux= valid_epoch_amp(valid_loader, model, loss)\n",
    "        score= dice_mask\n",
    "        print(f'train_loss: {round(train_loss, 5)}')\n",
    "        print(f'valid_loss: {round(valid_loss, 5)},\\\n",
    "                vali_score: {round(score, 5)},\\\n",
    "                valid_aux: {dice_aux}')\n",
    "    else: \n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(valid_loader)\n",
    "        score= 1-valid_logs['dice_loss']\n",
    "        print('vali_score: ', round(score, 5))\n",
    "\n",
    "    ## save best model\n",
    "    if max_score < score:\n",
    "        max_score = score\n",
    "        torch.save(model, f\"{CFG['save_model']}/model_cv{CFG['fold']}_best.pth\")\n",
    "        print('Model saved at: ', round(max_score, 5))\n",
    "        \n",
    "    ## save model every epoch\n",
    "    torch.save(model, f\"{CFG['save_model']}/model_cv{CFG['fold']}_ep{i}.pth\")\n",
    "\n",
    "    ##adjust lr\n",
    "#     if i == 70:\n",
    "#         optimizer.param_groups[0]['lr'] = 1e-4\n",
    "#         print(f\"Decrease decoder learning rate to {optimizer.param_groups[0]['lr']}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
