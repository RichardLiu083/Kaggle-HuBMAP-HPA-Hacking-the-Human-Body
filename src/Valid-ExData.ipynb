{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.cuda import amp\n",
    "import timm\n",
    "from pytorch_toolbelt.inference import tta\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "from monai.inferers import sliding_window_inference\n",
    "import shutil\n",
    "from tifffile import imread\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000000\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6363b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape, color=1):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = color\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def read_rgb_img(img_path):\n",
    "    img= imread(img_path)\n",
    "    img= np.squeeze(img)\n",
    "    if img.shape[0]==3: img= np.transpose(img, (1,2,0))\n",
    "    orign_shape= img.shape[:2][::-1]\n",
    "    return img, orign_shape\n",
    "\n",
    "def get_test_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.df = df\n",
    "        self.image_path = df['image_path'].values\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_path[index]\n",
    "        img, ori_shape= read_rgb_img(img_path)\n",
    "        \n",
    "        ## scale adjust\n",
    "        img_size= (img.shape[0], img.shape[1])\n",
    "        scale= CFG['img_scale'][CFG['organ']]\n",
    "        scale= int(scale)\n",
    "        img= cv2.resize(img, (img_size[1]//scale, img_size[0]//scale))\n",
    "        \n",
    "        img = self.transforms(image=img)[\"image\"]\n",
    "        return {\n",
    "            'img_path': img_path,\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "            'ori_shape': torch.tensor(ori_shape),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac96bc",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: os.mkdir('valid_temp_2')\n",
    "except: pass\n",
    "shutil.rmtree('valid_temp_2')\n",
    "os.mkdir('valid_temp_2')\n",
    "os.mkdir('valid_temp_2/img')\n",
    "os.mkdir('valid_temp_2/gt')\n",
    "os.mkdir('valid_temp_2/pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'fold': 0,\n",
    "#     'organ': 'kidney',\n",
    "    'organ': 'largeintestine',\n",
    "    \n",
    "    'window_size': 768,\n",
    "    'img_scale': {\n",
    "        'kidney': (4/1.25),\n",
    "        'largeintestine': (2.5),\n",
    "    },\n",
    "    \n",
    "    'TTA': True,\n",
    "    'model': None,\n",
    "    'show_result': False,\n",
    "}\n",
    "CFG['model']= f\"./train_model/model_cv{CFG['fold']}_best.pth\"\n",
    "# CFG['model']= f\"./train_model/model_cv{CFG['fold']}_ep25.pth\"\n",
    "# CFG['model']= f\"./test_model/effb7_w768_cv0_best/model_cv{CFG['fold']}_best.pth\"\n",
    "# CFG['model']= f\"./test_model/effb7_w768_0.58\"\n",
    "\n",
    "CFG['model']= [torch.load(CFG['model'], map_location= 'cuda:0')]\n",
    "# CFG['model']= [torch.load(m, map_location= 'cuda:0') for m in glob.glob(f\"{CFG['model']}/**/*pth\", recursive=True)[-5:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3485159",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdecfc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CFG['organ']=='kidney': df= pd.read_csv('./Data/ex_data_kidney.csv')\n",
    "if CFG['organ']=='largeintestine': df= pd.read_csv('./Data/ex_data_largeintestine.csv')\n",
    "df['fold']= 0\n",
    "valid_df= df.fillna('')\n",
    "\n",
    "valid_dataset= Customize_Dataset(valid_df.iloc[:5], get_test_transform())\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "print(f'valid dataset: {len(valid_dataset)}')\n",
    "valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277378a8",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, img, ori_shape):\n",
    "    img= img.cuda()\n",
    "    for i, m in enumerate(model):\n",
    "        with torch.no_grad():\n",
    "            m.eval()\n",
    "            if CFG['TTA']:\n",
    "                imgs= torch.cat([img, img.flip(-1), img.flip(-2), img.flip(-1).flip(-2)], dim=0)\n",
    "                pred= sliding_window_inference(imgs, \n",
    "                                               (CFG['window_size'], CFG['window_size']), \n",
    "                                               sw_batch_size= 2, \n",
    "                                               predictor= m,\n",
    "                                               mode= 'gaussian',\n",
    "                                               overlap= 0.25)\n",
    "                pred= (pred[0] + pred[1].flip(-1) + pred[2].flip(-2) + pred[3].flip(-1).flip(-2) ) / 4\n",
    "            else:\n",
    "                pred= sliding_window_inference(img, \n",
    "                                               (CFG['window_size'], CFG['window_size']), \n",
    "                                               sw_batch_size= 2, \n",
    "                                               predictor= m,\n",
    "                                               mode= 'gaussian',\n",
    "                                               overlap= 0.25)[0]\n",
    "                \n",
    "        if pred.shape[0]!=1:\n",
    "            if i==0: preds= pred.softmax(dim=0)\n",
    "            else: preds+= pred.softmax(dim=0)\n",
    "        else:\n",
    "            if i==0: preds= pred.sigmoid()\n",
    "            else: preds+= pred.sigmoid()\n",
    "                \n",
    "    pred= preds/len(model)\n",
    "    pred= pred.cpu().permute(1,2,0).numpy()\n",
    "    if pred.shape[2]!=1:\n",
    "        if 'kidney'==CFG['organ']:\n",
    "            pred= pred[..., 4:5]\n",
    "        else:\n",
    "            pred= pred[..., 5:6]\n",
    "    pred= cv2.resize(pred, tuple(ori_shape))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125ed0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indx= 0\n",
    "for i, data in enumerate(tqdm(valid_loader)):\n",
    "    for j in range(len(data['image'])):\n",
    "        img_path= data['img_path'][j]\n",
    "        shutil.copy(img_path, f'valid_temp_2/img/{indx}.tiff')\n",
    "        img= data['image'][j]\n",
    "        ori_shape= data['ori_shape'][j]\n",
    "        \n",
    "        mask_path= valid_df.loc[indx, 'mask_path']\n",
    "        shutil.copy(mask_path, f'valid_temp_2/gt/{indx}.png')\n",
    "        \n",
    "        ## inference\n",
    "        img= torch.unsqueeze(img, dim= 0)\n",
    "        pred_mask= inference(CFG['model'], img, ori_shape.numpy())\n",
    "        pred_mask*= 255\n",
    "        \n",
    "        im= Image.fromarray(pred_mask.astype(np.uint8))\n",
    "        im.save(f'valid_temp_2/pt/{indx}.png')\n",
    "        del pred_mask\n",
    "        \n",
    "        indx+= 1\n",
    "        if CFG['show_result']:\n",
    "            ## show result\n",
    "            plt.figure(figsize=(15,15))\n",
    "            plt.subplot(1,4,1)\n",
    "            img= np.array(Image.open(img_path))\n",
    "            plt.title('image', color= 'b')\n",
    "            plt.imshow(img)\n",
    "\n",
    "            plt.subplot(1,4,2)\n",
    "            plt.title('predict_mask', color= 'b')\n",
    "            plt.imshow(pred_mask)\n",
    "\n",
    "            pred_mask= cv2.cvtColor(pred_mask, cv2.COLOR_GRAY2RGB)\n",
    "            pred_mask[:,:,1:]= 0\n",
    "            mix_img= (img*0.5).astype(np.uint8) + (pred_mask*0.5).astype(np.uint8)\n",
    "            plt.subplot(1,4,3)\n",
    "            plt.title('mix_iamge', color= 'b')\n",
    "            plt.imshow(mix_img)\n",
    "\n",
    "            gt_mask= cv2.cvtColor(gt_mask, cv2.COLOR_GRAY2RGB)\n",
    "            gt_mask[:,:,1:]= 0\n",
    "            mix_img= (img*0.5).astype(np.uint8) + (gt_mask*0.5).astype(np.uint8)\n",
    "            plt.subplot(1,4,4)\n",
    "            plt.title('gt_mask', color= 'b')\n",
    "            plt.imshow(mix_img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7077d",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cccf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt= glob.glob('valid_temp_2/gt/**.png')\n",
    "pt= glob.glob('valid_temp_2/pt/**.png')\n",
    "\n",
    "from pytorch_toolbelt import losses as L\n",
    "dice_loss= L.DiceLoss(mode= 'binary', from_logits=False)\n",
    "\n",
    "def evaluate(thr= 0.5):\n",
    "    dices= []\n",
    "    for i in tqdm(range(len(gt))):\n",
    "        pt_mask= np.array(Image.open(pt[i]).convert('L')).astype(np.uint8)/255\n",
    "        pt_mask= cv2.resize(pt_mask, (2048,2048))\n",
    "        pt_mask= np.expand_dims(pt_mask, axis=0)\n",
    "        pt_mask[pt_mask>=thr]= 1\n",
    "        pt_mask[pt_mask<thr]= 0\n",
    "        gt_mask= np.array(Image.open(gt[i]).convert('L')).astype(np.uint8)/255\n",
    "        gt_mask= cv2.resize(gt_mask, (2048,2048))\n",
    "        gt_mask= np.expand_dims(gt_mask, axis=0)\n",
    "\n",
    "        loss= dice_loss( torch.tensor(pt_mask), torch.tensor(gt_mask) )\n",
    "        score= 1-loss\n",
    "        dices.append(score)\n",
    "        del pt_mask\n",
    "        del gt_mask\n",
    "\n",
    "    return np.mean(dices)\n",
    "\n",
    "scores= []\n",
    "for thr in range(1, 10):\n",
    "    thr/=10\n",
    "    print(f'thr= {thr}')\n",
    "    dice= evaluate(thr)\n",
    "    scores.append(dice)\n",
    "    if thr==0.5:\n",
    "        print(f'thr_0.5: {dice}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1014c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
