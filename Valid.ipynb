{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb0a5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.cuda import amp\n",
    "import timm\n",
    "from pytorch_toolbelt.inference import tta\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "from monai.inferers import sliding_window_inference\n",
    "import shutil\n",
    "from tifffile import imread\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be6363b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape, color=1):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = color\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def read_rgb_img(img_path):\n",
    "#     img_path= img_path.replace('train_images', 'train_images_domain_shift')\n",
    "    img= imread(img_path)\n",
    "    orign_shape= img.shape[:2][::-1]\n",
    "    return img, orign_shape\n",
    "\n",
    "def get_test_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        self.df = df\n",
    "        self.image_path = df['image_path'].values\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_path[index]\n",
    "        img, ori_shape= read_rgb_img(img_path)\n",
    "        \n",
    "        ## scale adjust\n",
    "        img_size= min(img.shape[0], img.shape[1])\n",
    "        img_size= img_size//CFG['img_scale']\n",
    "        img_size= CFG['window_size'] if img_size < CFG['window_size'] else img_size\n",
    "        img= cv2.resize(img, (img_size, img_size))\n",
    "        \n",
    "        img = self.transforms(image=img)[\"image\"]\n",
    "        return {\n",
    "            'img_path': img_path,\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "            'ori_shape': torch.tensor(ori_shape),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac96bc",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "488b92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('valid_temp')\n",
    "os.mkdir('valid_temp')\n",
    "os.mkdir('valid_temp/gt')\n",
    "os.mkdir('valid_temp/pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1755a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'fold': 3,\n",
    "    'img_scale': 4,\n",
    "    'window_size': 768,\n",
    "    'TTA': False,\n",
    "    'model': None,\n",
    "    'show_result': False,\n",
    "}\n",
    "# CFG['model']= f\"./train_model/model_cv{CFG['fold']}_best.pth\"\n",
    "# CFG['model']= f\"./train_model/model_cv{CFG['fold']}_ep81.pth\"\n",
    "CFG['model']= f\"./test_model/effb7_w768_0.54/model_cv{CFG['fold']}_best.pth\"\n",
    "\n",
    "CFG['model']= [torch.load(CFG['model'], map_location= 'cuda:0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3485159",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcdecfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid dataset: 70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>rle</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>image_path</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10044</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Data/train_images/10044.tiff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10274</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Data/train_images/10274.tiff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11645</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>2867</td>\n",
       "      <td>2867</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1971766 32 1974633 34 1977499 36 1980366 37 19...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Data/train_images/11645.tiff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11890</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1297230 32 1300222 46 1303215 60 1306213 63 13...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Data/train_images/11890.tiff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1220</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1429797 16 1432793 21 1435791 23 1438789 27 14...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Data/train_images/1220.tiff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id           organ data_source  img_height  img_width  pixel_size  \\\n",
       "0  10044        prostate         HPA        3000       3000         0.4   \n",
       "1  10274        prostate         HPA        3000       3000         0.4   \n",
       "2  11645          spleen         HPA        2867       2867         0.4   \n",
       "3  11890  largeintestine         HPA        3000       3000         0.4   \n",
       "4   1220            lung         HPA        3000       3000         0.4   \n",
       "\n",
       "   tissue_thickness                                                rle   age  \\\n",
       "0                 4  1459676 77 1462675 82 1465674 87 1468673 92 14...  37.0   \n",
       "1                 4  715707 2 718705 8 721703 11 724701 18 727692 3...  76.0   \n",
       "2                 4  1971766 32 1974633 34 1977499 36 1980366 37 19...  74.0   \n",
       "3                 4  1297230 32 1300222 46 1303215 60 1306213 63 13...  79.0   \n",
       "4                 4  1429797 16 1432793 21 1435791 23 1438789 27 14...  59.0   \n",
       "\n",
       "      sex                    image_path  fold  \n",
       "0    Male  Data/train_images/10044.tiff     3  \n",
       "1    Male  Data/train_images/10274.tiff     3  \n",
       "2  Female  Data/train_images/11645.tiff     3  \n",
       "3  Female  Data/train_images/11890.tiff     3  \n",
       "4    Male   Data/train_images/1220.tiff     3  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('./Data/train.csv')\n",
    "\n",
    "valid_df= df[df['fold']==CFG['fold']].reset_index(drop=True)\n",
    "print(f'valid dataset: {len(valid_df)}')\n",
    "\n",
    "valid_dataset= Customize_Dataset(valid_df, get_test_transform())\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277378a8",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81f1349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, img, ori_shape):\n",
    "    img= img.cuda()\n",
    "    for i, m in enumerate(model):\n",
    "        with torch.no_grad():\n",
    "            m.eval()\n",
    "            if CFG['TTA']:\n",
    "                pred_1= m(img)[0]\n",
    "                pred_2= m(img.flip(-1))[0].flip(-1)\n",
    "                pred_3= m(img.flip(-2))[0].flip(-2)\n",
    "                pred= (pred_1 + pred_2 + pred_3) / 3\n",
    "            else:\n",
    "                pred= sliding_window_inference(img, \n",
    "                                               (CFG['window_size'], CFG['window_size']), \n",
    "                                               sw_batch_size= 2, \n",
    "                                               predictor= m,\n",
    "                                               mode= 'gaussian',\n",
    "                                               overlap= 0.25)[0]\n",
    "                \n",
    "        if i==0: preds= pred\n",
    "        else: preds+= pred\n",
    "    pred= preds/len(model)\n",
    "    pred= pred.sigmoid().cpu().permute(1,2,0).numpy()\n",
    "    pred= cv2.resize(pred, tuple(ori_shape))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d125ed0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db9fb6dcf5242809a8ea85e46742ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(tqdm(valid_loader)):\n",
    "    for j in range(len(data['image'])):\n",
    "        img_path= data['img_path'][j]\n",
    "        img= data['image'][j]\n",
    "        ori_shape= data['ori_shape'][j]\n",
    "        \n",
    "        img_size= Image.open(img_path).size[::-1]\n",
    "        id_= img_path.split('/')[-1].split('.')[0]\n",
    "        rle= valid_df.loc[valid_df['id']==int(id_), 'rle'].values[0]\n",
    "        gt_mask= rle_decode(rle, img_size)\n",
    "        \n",
    "        ## inference\n",
    "        img= torch.unsqueeze(img, dim= 0)\n",
    "        pred_mask= inference(CFG['model'], img, ori_shape.numpy())\n",
    "    \n",
    "        pred_mask= pred_mask*255\n",
    "        im= Image.fromarray(pred_mask.astype(np.uint8))\n",
    "        im.save(f'valid_temp/pt/{id_}.png')\n",
    "        gt_mask= gt_mask*255\n",
    "        im= Image.fromarray(gt_mask.astype(np.uint8))\n",
    "        im.save(f'valid_temp/gt/{id_}.png')\n",
    "        \n",
    "        if CFG['show_result']:\n",
    "            ## show result\n",
    "            plt.figure(figsize=(15,15))\n",
    "            plt.subplot(1,4,1)\n",
    "            img= np.array(Image.open(img_path))\n",
    "            plt.title('image', color= 'b')\n",
    "            plt.imshow(img)\n",
    "\n",
    "            plt.subplot(1,4,2)\n",
    "            plt.title('predict_mask', color= 'b')\n",
    "            plt.imshow(pred_mask)\n",
    "\n",
    "            pred_mask= cv2.cvtColor(pred_mask, cv2.COLOR_GRAY2RGB)\n",
    "            pred_mask[:,:,1:]= 0\n",
    "            mix_img= (img*0.5).astype(np.uint8) + (pred_mask*0.5).astype(np.uint8)\n",
    "            plt.subplot(1,4,3)\n",
    "            plt.title('mix_iamge', color= 'b')\n",
    "            plt.imshow(mix_img)\n",
    "\n",
    "            gt_mask= cv2.cvtColor(gt_mask, cv2.COLOR_GRAY2RGB)\n",
    "            gt_mask[:,:,1:]= 0\n",
    "            mix_img= (img*0.5).astype(np.uint8) + (gt_mask*0.5).astype(np.uint8)\n",
    "            plt.subplot(1,4,4)\n",
    "            plt.title('gt_mask', color= 'b')\n",
    "            plt.imshow(mix_img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7077d",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cccf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr= 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560971b871184685910fb5291043e613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt= glob.glob('valid_temp/gt/**.png')\n",
    "pt= glob.glob('valid_temp/pt/**.png')\n",
    "\n",
    "from pytorch_toolbelt import losses as L\n",
    "dice_loss= L.DiceLoss(mode= 'binary', from_logits=False)\n",
    "\n",
    "def evaluate(thr= 0.5):\n",
    "    dice_organ= {\n",
    "        'prostate': [],\n",
    "        'spleen': [],\n",
    "        'lung': [],\n",
    "        'kidney': [],\n",
    "        'largeintestine': [],\n",
    "    }\n",
    "    dices= []\n",
    "    for i in tqdm(range(len(gt))):\n",
    "        id_= pt[i].split('\\\\')[-1].split('.')[0]\n",
    "        organ= df[df['id']==int(id_)]['organ'].values[0]\n",
    "\n",
    "        pt_mask= np.array(Image.open(pt[i]).convert('L'))/255\n",
    "        pt_mask= np.expand_dims(pt_mask, axis=0)\n",
    "        pt_mask[pt_mask>=thr]= 1\n",
    "        pt_mask[pt_mask<thr]= 0\n",
    "        gt_mask= np.array(Image.open(gt[i]).convert('L'))/255\n",
    "        gt_mask= np.expand_dims(gt_mask, axis=0)\n",
    "\n",
    "        loss= dice_loss( torch.tensor(pt_mask), torch.tensor(gt_mask) )\n",
    "        score= 1-loss\n",
    "        dices.append(score)\n",
    "\n",
    "        dice_organ[organ].append(score)\n",
    "\n",
    "    for key in dice_organ.keys():\n",
    "        dice_organ[key]= round( np.mean(dice_organ[key]), 3)\n",
    "        \n",
    "    return np.mean(dices), dice_organ\n",
    "\n",
    "scores= []\n",
    "for thr in range(1, 10):\n",
    "    thr/=10\n",
    "    print(f'thr= {thr}')\n",
    "    dice, organ_dice= evaluate(thr)\n",
    "    scores.append(dice)\n",
    "    if thr==0.5:\n",
    "        print(f'dice_score: {np.mean(dice)}')\n",
    "        print(f'dice_organ:')\n",
    "        display(organ_dice)\n",
    "        \n",
    "avg_dice= []\n",
    "for (key, value) in organ_dice.items():\n",
    "    avg_dice.append(value)\n",
    "print(f'avg_dice: {np.mean(avg_dice)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_score_thr= []\n",
    "cv_score_thr.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_score_thr[0])\n",
    "plt.plot(cv_score_thr[1])\n",
    "plt.plot(cv_score_thr[2])\n",
    "plt.plot(cv_score_thr[3])\n",
    "plt.plot(cv_score_thr[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f36c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa_lb= 0.22\n",
    "hpa_lb_norm= hpa_lb*(291/81)\n",
    "print(f'hpa_norm: {hpa_lb_norm}')\n",
    "\n",
    "hubmap_lb= 0.54\n",
    "hubmap_lb_norm= hubmap_lb*(291/210)\n",
    "print(f'hubmap_norm: {hubmap_lb_norm}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
